/*
 * Qâ€‘SCI LLM Evaluator
 *
 * This module replaces the lightweight heuristic evaluator with an
 * evaluation powered by OpenAI's GPT model.  It sends the paper
 * content to the OpenAI Chat Completion API along with a carefully
 * constructed prompt and expects the model to return a JSON
 * structure describing the quality of the paper.  The output is
 * identical in shape to the original evaluator: a quality score
 * (0â€“100), a traffic light (ðŸŸ¢/ðŸŸ¡/ðŸ”´), and arrays of positive and
 * negative aspects with supporting source text snippets.  To use
 * this evaluator, you must provide your own OpenAI API key.
 */

// Define a fallback evaluator early.  If this script fails to initialize due
// to a syntax error (e.g. misâ€‘formatted API key), the popup will still
// find a qsciEvaluatePaper function and report a meaningful error rather
// than "window.qsciEvaluatePaper is not a function".  The fallback
// returns a rejected promise with an error.
if (typeof window !== 'undefined' && typeof window.qsciEvaluatePaper === 'undefined') {
  window.qsciEvaluatePaper = function() {
    return Promise.reject(new Error('Qâ€‘SCI LLM evaluator is not initialized. Please ensure the extension has loaded correctly and that your OpenAI API key is set via the extension settings.'));
  };
}

(() => {
  // ---------------------------------------------------------------------------
  // Configuration
  //
  // The OpenAI API key will be retrieved from chrome.storage at
  // runtime.  Do not edit this file to insert your key; instead set
  // your API key via the extension's settings page.  See
  // options.html/options.js for details.
  let OPENAI_API_KEY = null;

  // Model to use.  You can adjust this if you have access to
  // different models (e.g. 'gpt-4-turbo', 'gpt-3.5-turbo-0125').
  const MODEL_NAME = 'gpt-3.5-turbo-0125';

  // Temperature setting for the model.  Lower values make the output
  // more deterministic.
  const TEMPERATURE = 0.0;

  // API endpoint for OpenAI chat completions
  const OPENAI_API_ENDPOINT = 'https://api.openai.com/v1/chat/completions';

  /**
   * Build the prompt for the OpenAI model.  The system message
   * instructs the model to behave as a scientific paper quality
   * evaluator and to respond with JSON in a specific format.  The
   * user message includes the title, source URL and the paper text to
   * be evaluated.
   *
   * @param {string} title - Paper title
   * @param {string} sourceUrl - URL of the paper
   * @param {string} text - Paper text content
   * @returns {Array} messages suitable for OpenAI chat completion API
   */
  function buildMessages(title, sourceUrl, text) {
    const system = `You are Qâ€‘SCI, an expert scientific publication quality evaluator.\n\n` +
      `When given the full text of a scientific publication, you must assess the overall quality of the study using standard evidenceâ€‘grading principles. ` +
      `Focus on the actual paper content only â€” ignore the reference list and citations. ` +
      `Identify study design features (e.g. randomized controlled trial, crossover, metaâ€‘analysis, observational study), sample size and clear reporting practices. ` +
      `Consider whether the study is blinded, placebo controlled or nonâ€‘inferiority, whether it follows reporting guidelines (e.g. CONSORT for trials, PRISMA for reviews, STROBE for observational studies), and whether sample sizes are adequate. ` +
      `Assign a quality score between 0 and 100. 90â€“100 = ðŸŸ¢ Green, 70â€“89 = ðŸŸ¡ Amber, below 70 = ðŸ”´ Red. ` +
      `Then provide at least three positive aspects and three negative aspects. Each aspect must be directly supported by a snippet of source text taken verbatim from the paper. ` +
      `For each aspect, set the 'aspect' field to a short summary of the point and set 'source_text' to the exact sentence or sentences from the paper that support it. ` +
      `Do not invent content: every aspect and snippet must be present in the provided paper text. ` +
      `Ignore the reference list entirely when choosing aspects and source text. ` +
      `Return your answer strictly as a JSON object with the following keys:\n\n` +
      `quality_percentage (number),\n` +
      `traffic_light (string, one of \"ðŸŸ¢ Green\", \"ðŸŸ¡ Amber\", \"ðŸ”´ Red\"),\n` +
      `positive_aspects (array of objects with keys 'aspect' and 'source_text'),\n` +
      `negative_aspects (array of objects with keys 'aspect' and 'source_text')\n\n` +
      `Do not include any code block formatting, backticks or additional commentary.  Only output a single valid JSON object.`;

    const user = `Paper Title: ${title || 'Unknown Title'}\n` +
      `Source URL: ${sourceUrl || 'N/A'}\n\n` +
      `Paper Content (trimmed):\n${text || ''}`;

    return [
      { role: 'system', content: system },
      { role: 'user', content: user }
    ];
  }

  /**
   * Parse the response from OpenAI.  The API returns a JSON object
   * with choices, each containing a message.  This function
   * extracts the content, attempts to parse it as JSON, and returns
   * the resulting object.  It also normalizes the structure to
   * ensure compatibility with the extension.
   *
   * @param {any} responseJson - Parsed JSON response from API
   * @returns {any} Parsed evaluation object
   */
  function parseOpenAIResponse(responseJson) {
    try {
      const content = responseJson?.choices?.[0]?.message?.content || '';
      // Attempt to parse the content directly as JSON
      let parsed;
      try {
        parsed = JSON.parse(content.trim());
      } catch (inner) {
        // Remove common formatting markers like triple backticks or "json:" prefix
        const cleaned = content
          .replace(/^\s*```json\s*/i, '')
          .replace(/^\s*```\s*/i, '')
          .replace(/```\s*$/i, '')
          .trim();
        parsed = JSON.parse(cleaned);
      }
      // Ensure required keys exist and types are correct
      if (!parsed || typeof parsed !== 'object') throw new Error('Invalid JSON structure');
      const quality = typeof parsed.quality_percentage === 'number' ? parsed.quality_percentage : 0;
      const traffic = typeof parsed.traffic_light === 'string' ? parsed.traffic_light : 'ðŸŸ¡ Amber';
      const pos = Array.isArray(parsed.positive_aspects) ? parsed.positive_aspects : [];
      const neg = Array.isArray(parsed.negative_aspects) ? parsed.negative_aspects : [];
      return { quality_percentage: quality, traffic_light: traffic, positive_aspects: pos, negative_aspects: neg };
    } catch (e) {
      console.error('Qâ€‘SCI LLM Evaluator: Failed to parse OpenAI response', e);
      return null;
    }
  }

  /**
   * Evaluate a paper using OpenAI's chat completion API.  This function
   * builds the prompt, sends the request to OpenAI, parses the
   * response, and returns the evaluation.  If the API key is not
   * provided or an error occurs, the function will throw an error.
   *
   * @param {string} text - The paper text to evaluate
   * @param {string} title - The paper title
   * @param {string} sourceUrl - The URL of the paper
   * @returns {Promise<any>} A promise that resolves to the evaluation object
   */
  async function evaluate(text, title, sourceUrl) {
    console.log('Qâ€‘SCI LLM Evaluator: Starting evaluation...');
    
    if (!text || text.trim().length < 50) {
      throw new Error('Insufficient text provided for analysis');
    }

    // Fetch the OpenAI API key from the backend instead of local storage
    // This ensures the key is managed centrally and users don't need to manually enter it
    let apiKey;
    try {
      console.log('Qâ€‘SCI LLM Evaluator: Fetching API key from backend...');
      console.log('Qâ€‘SCI LLM Evaluator: window.QSCIAuth available:', typeof window.QSCIAuth !== 'undefined');
      console.log('Qâ€‘SCI LLM Evaluator: getOpenAIApiKey function available:', typeof window.QSCIAuth?.getOpenAIApiKey === 'function');
      
      // Check if QSCIAuth is available (it should be loaded before this script)
      if (typeof window.QSCIAuth === 'undefined' || typeof window.QSCIAuth.getOpenAIApiKey !== 'function') {
        const errorMsg = 'Authentication module not available. Please ensure you are logged in and the extension is properly loaded.';
        console.error('Qâ€‘SCI LLM Evaluator:', errorMsg);
        throw new Error(errorMsg);
      }
      
      console.log('Qâ€‘SCI LLM Evaluator: Calling getOpenAIApiKey()...');
      apiKey = await window.QSCIAuth.getOpenAIApiKey();
      
      if (!apiKey) {
        const errorMsg = 'Failed to retrieve API key from backend. Please try logging in again.';
        console.error('Qâ€‘SCI LLM Evaluator:', errorMsg);
        throw new Error(errorMsg);
      }
      
      console.log('Qâ€‘SCI LLM Evaluator: API key fetched successfully (length:', apiKey.length, ')');
    } catch (error) {
      console.error('Qâ€‘SCI LLM Evaluator: Error fetching API key:', error);
      console.error('Qâ€‘SCI LLM Evaluator: Error stack:', error.stack);
      throw new Error(`Unable to retrieve API key from backend: ${error.message}`);
    }

    const messages = buildMessages(title, sourceUrl, text);
    const body = JSON.stringify({
      model: MODEL_NAME,
      messages: messages,
      temperature: TEMPERATURE,
      // Provide a max_tokens to cap the response length.  700 tokens is
      // enough for our JSON structure and some additional content.
      max_tokens: 700
    });

    const headers = {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`
    };

    // Perform the API request using fetch.  The fetch API is available
    // in the Chrome extension context.  Host permissions for
    // https://api.openai.com/* must be declared in manifest.json.
    const response = await fetch(OPENAI_API_ENDPOINT, {
      method: 'POST',
      headers: headers,
      body: body
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`OpenAI API request failed: ${response.status} ${response.statusText}\n${errorText}`);
    }
    const json = await response.json();
    const parsed = parseOpenAIResponse(json);
    if (!parsed) {
      throw new Error('Failed to parse evaluation from OpenAI response');
    }
    return parsed;
  }

  // Expose the evaluator on the window object.  The popup script will
  // call window.qsciEvaluatePaper() just like with the heuristics
  // evaluator.  Note that this function returns a promise, so the
  // popup code must handle asynchronous evaluation.
  window.qsciEvaluatePaper = evaluate;
})();